{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d49684-2a2e-44f6-b1c1-14ae38f307c8",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b30345-8175-485c-8a92-9b04c611317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.virtualenvs\\Project-v4EWajkE\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\user\\.virtualenvs\\Project-v4EWajkE\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import minsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfab572f-74f9-44e7-8dbb-cccfd579e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/final_data_with_IDs.csv')\n",
    "\n",
    "documents = df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49255aa6-4022-41a9-b49c-bf5fc92010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'Chunked_Content': \"when you eat it alone?. Good idea to eat it once wuth honey and once alone My kids eat it with the meal.They aren't at home btw meals I will do it during week end Yesterday I had nausea after several hours passed from second meal.Today I had zero hunger until 20h+ passed after previous that meal Today I made only one typical meal enhanced with 4 egg yolks\",\n",
       " 'number of sentences': 2,\n",
       " 'number of words': 69,\n",
       " 'Keywords': \"['pass', 'meal', 'home', 'nausea', 'honey', 'week', 'hunger', 'second', 'previous', 'btw', '20h+', 'kid', 'good', 'typical', 'idea', 'enhance', 'zero', '4', 'today', 'eat', 'yolk', 'egg', 'yesterday', 'wuth', 'hour', 'end']\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d07a1f-7d0d-44f1-a77d-96b8d79f0055",
   "metadata": {},
   "source": [
    "### Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29e0bad-a82e-4b4d-bbbd-07bbf906903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['Chunked_Content'],\n",
    "    keyword_fields=['Keywords']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983e54e9-2c7b-4848-8482-19d4cf589a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x2931c120ce0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341a55cb-be6e-48ac-9a8f-15e72cae0f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x2931c120ce0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a56dcae-f7aa-4b0a-902e-02f31686f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chunked_Content']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f726cf-66d5-48f3-b9f0-0ca6e0a5569c",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb1a91f-efac-4e76-8671-b02840b45561",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "477dc7f6-b597-4938-b478-e1c64e32587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I want to lose belly fat. What shall I eat?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ed55640-6a68-4d51-bca4-872f8a6d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da200554-c9b4-4c25-bb3c-2669be2b548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6250adf1-12b3-480f-b33d-c3ec6608b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Losing belly fat involves a combination of dietary changes, regular physical activity, and possibly some lifestyle adjustments. Here are some dietary recommendations to help you on your journey:\\n\\n### Foods to Eat:\\n\\n1. **High-Protein Foods**:\\n   - **Lean meats**: Chicken breast, turkey, and lean cuts of beef.\\n   - **Fish**: Salmon, mackerel, and tuna.\\n   - **Legumes**: Lentils, chickpeas, and beans.\\n   - **Dairy**: Greek yogurt, cottage cheese, and low-fat dairy options.\\n   - **Eggs**: Particularly the whites, but the whole egg can also be beneficial.\\n\\n2. **Fiber-Rich Foods**:\\n   - **Fruits**: Apples, berries, oranges, and pears.\\n   - **Vegetables**: Leafy greens, broccoli, carrots, and Brussels sprouts.\\n   - **Whole Grains**: Oats, quinoa, brown rice, and whole-wheat bread/pasta.\\n   - **Nuts and Seeds**: Almonds, chia seeds, flaxseeds, and walnuts.\\n\\n3. **Healthy Fats**:\\n   - **Avocado**: Rich in monounsaturated fats.\\n   - **Olive Oil**: A good source of heart-healthy fats.\\n   - **Fatty Fish**: Like salmon, which is high in omega-3 fatty acids.\\n   - **Nuts and Seeds**: In moderation, they provide healthy fats and energy.\\n\\n4. **Complex Carbohydrates**:\\n   - **Whole-Grain Products**: Brown rice, quinoa, and whole-wheat products.\\n   - **Starchy Vegetables**: Sweet potatoes, lentils, and peas.\\n\\n5. **Hydrating Foods**:\\n   - **Water**: Aim for at least 8 glasses a day.\\n   - **Herbal Teas**: Green tea and peppermint tea can also aid digestion and metabolism.\\n   - **Watery Fruits and Vegetables**: Cucumbers, watermelon, and celery.\\n\\n### Foods to Avoid:\\n1. **Sugary Foods and Beverages**:\\n   - **Soda** and **fruit juices** with added sugars.\\n   - **Candies**, **pastries**, and **cakes**.\\n\\n2. **Refined Carbohydrates**:\\n   - **White bread**, **white rice**, and **pasta** made from refined flour.\\n\\n3. **Trans Fats**:\\n   - Found in some margarine, packaged baked goods, and fried foods.\\n\\n4. **Processed Foods**:\\n   - Chips, crackers, and other snack foods high in salt and unhealthy fats.\\n\\n5. **High-Calorie, Low-Nutrient Foods**:\\n   - Fast food items, many commercially-prepared sauces, and dressings.\\n\\n### Additional Tips:\\n1. **Portion Control**: Be mindful of portion sizes to avoid overeating.\\n2. **Clean Eating**: Aim for whole, unprocessed foods as much as possible.\\n3. **Frequent, Balanced Meals**: Eating smaller, balanced meals more frequently can help stabilize blood sugar levels and reduce overeating.\\n4. **Mindful Eating**: Pay attention to hunger and fullness cues; avoid eating out of boredom or stress.\\n5. **Limit Alcohol**: Alcohol can add empty calories and affect your metabolism.\\n\\n### Exercise and Lifestyle:\\n- **Cardio Exercise**: Activities such as jogging, cycling, or swimming can help burn calories and reduce overall body fat.\\n- **Strength Training**: Building muscle can increase your resting metabolic rate, aiding in fat loss.\\n- **Sleep**: Aim for 7-9 hours of quality sleep per night, as poor sleep can affect weight and fat distribution.\\n- **Stress Management**: High stress levels can lead to increased abdominal fat due to higher cortisol levels. Practices such as yoga, meditation, or deep-breathing exercises can be helpful.\\n\\nConsulting a healthcare provider or nutritionist before starting any new diet or exercise program is always a good idea, especially if you have underlying health conditions.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM response\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38c4f49c-a547-4515-8fbc-2b36a5595d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "Chunked_Content: {Chunked_Content}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c907faaf-a485-46ad-9060-124443fa2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "397591c9-4df9-47ab-b277-01011c0603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='How to lower blood pressure?'\n",
    "def rag(query, model='gpt-3.5-turbo'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b57145f-c05e-46a9-b245-77bfb93a3d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information from the primal diet database, the best way to manage high blood pressure is to address the underlying causes such as being overweight, having pressure on veins and arteries, or dealing with congestion. High blood pressure is seen as a natural response by the body to ensure proper blood flow, especially when there are blockages or other issues. Overweight individuals or those with hardened arteries and veins may need high blood pressure to maintain circulation.\n",
      "\n",
      "Instead of trying to lower high blood pressure artificially, it is recommended to address the root cause of the issue. Consuming fresh raw grapefruit, fresh raw cucumber, and fresh raw garlic are suggested as natural ways to help soothe arterial health and stabilize blood pressure. It is mentioned that high blood pressure medication or homeopathy to lower blood pressure may lead to clotting and other complications due to decreased blood flow.\n",
      "\n",
      "In conclusion, managing high blood pressure naturally involves addressing lifestyle factors such as diet, weight, and circulation, while recognizing the importance of high blood pressure in certain situations to ensure proper blood flow.\n"
     ]
    }
   ],
   "source": [
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bdb0d2-4ca6-4564-84e7-6cc4ee20a935",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cb4f7e6e-112a-4edd-a582-e84e82bc3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('../data/clean_data/ground-truth-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6c70fcd-2378-4447-8434-1e5e37bc679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14910\n"
     ]
    }
   ],
   "source": [
    "print(len(df_questions))\n",
    "# I will slice it to save time\n",
    "df_questions_5000=df_questions.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9e4f21d-fd20-4e3a-866a-97eee735988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=df_questions_5000.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd268389-6545-444a-985a-5cee677df68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the two lube formulas you mentioned?\n",
      "What is the maximum amount of fat I should consume daily?\n",
      "How many days did it take you to reach a weight of 66 kg?\n",
      "Did you triple your intake of something, and what was it?\n",
      "Can you tell me more about what else you included in your diet?\n",
      "Are there additional resources available in AV books?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)\n",
    "for q in ground_truth[0:6]:\n",
    "    print(q['question'])\n",
    "type(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d641e326-5c48-46b1-97fb-93a06837dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc09a27d-e890-490a-912b-f08f9922ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c93510cd-f3ad-429e-a18f-79e7e7348425",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['Chunked_Content'],\n",
    "    keyword_fields=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18641e86-ca64-4539-bc05-c74e93af163d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca414d53-c401-4f1f-b059-0d901590711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x24136666f60>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "673d9136-8be6-4e9d-8991-588da22fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b3eebcc9-f0e5-47df-83d9-23491b86fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b208267a-e1aa-43d5-8aaf-e7528fc8a1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a35eff827734bf2900e4aadfae56a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.365, 'mrr': 0.21138730158730154}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1747994a-fdd1-4c68-9e06-ee7e763ccd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e34104f04a471680dd1a6a842550e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b26956-ce63-416f-85bb-9c8154609701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'hit_rate': 0.365, 'mrr': 0.21138730158730154} # with 1000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cccd83a8-b44b-443d-9a38-22e524e67054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}# with 5000 rows of ground-truth questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1ab90-92e8-4e8e-b4ce-91db57ff5abf",
   "metadata": {},
   "source": [
    "### Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64019bd7-fc1d-4485-b76a-001f0021e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_questions[:200]\n",
    "df_test = df_questions[200:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a81f8226-2c55-446e-a980-c4ad8c007f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c6dab3e-4fde-43f3-bfa2-9cdc178d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81c09c4c-228c-404e-ab87-21e4ce04c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4df0cc6-c6c3-41a7-99fb-f7e5ead85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'Chunked_Content': (0.0, 3.0),\n",
    "    'Keywords': (0.0, 3.0),\n",
    "    \n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d45dee4-ed23-4a5a-ba4f-300db9d29c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdf70804b444281827d90c4a9b0504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f59b527d9694034a2722d3673fe8132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547f1a32bf93415e8f738ff6a15672b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6480b661a4fd49d2970364129f854545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c58c6f4a846758b9e83d219957682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7667fef7455e48d584cf8d72c8306840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c6e2bb9b444753b1eceb1af993ed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b652c86761c14777b41f4be3d4873d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e553a9a64f4b83905576e2526a13a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8b32dc9ce94d0c819151efe408eec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8103c711cb40139e4842ce9488e3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c2fa2b36434bfea2073592201c6ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ad65a1df824d2395398b850ed3a584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e33562b78ad489b8c0a006ec03f6bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b440c7ee6104647846244d2c9af4628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bccfac0c72245f0909681ee48d5725c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e487f994a14fb2a6924a97c2522bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5028628ee1ac4994a553cd15004ea032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc959f0cda74c9aa631da9d04f9c2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda723fdcc3e48ac95d862c996bf5ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Chunked_Content': 1.4470935096658424, 'Keywords': 0.5503642620036224},\n",
       " 0.1790515873015873)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e61a1a7a-24d5-4393-addc-c878007d803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e63936c7f04464b00dcaa9b2c9efc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "    'Chunked_Content':1.4470935096658424, \n",
    "    'Keywords': 0.5503642620036224\n",
    "    \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3e339-07b4-4e28-80e2-632a770e5950",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a02ae322-57b2-4066-8331-b3e5e061bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb793c64-af79-4398-88c6-2b881799f996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55d2bf40-4fb6-49fa-a1ad-5d19c7fa47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 8436, 'question': 'What are the two lube formulas you mentioned?'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4991fe79-f4d0-4086-ae0e-efb27e40bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two lube formulas mentioned are milkshakes and custard.\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "question = record['question']\n",
    "answer_llm = rag(question)\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86abda30-f17c-4c3b-bb90-35227e37c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What are the two lube formulas you mentioned?\n",
      "Generated Answer: The two lube formulas mentioned are milkshakes and custard.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "964641f2-5950-4e88-88a2-5702cf756e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa07007e-f7f9-46df-b7a6-d5912d4429c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_questions.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "826ec05c-5d53-4d54-85ff-f68bae5bc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeee6fd1-cae7-4df5-8bd0-756b4429ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4ea24addc440259589448fb3cbf846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model='gpt-3.5-turbo') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22cddc4d-3dd0-4acf-bf38-d3c8c1d95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d09b74b1-4fc8-4c2c-96c6-666a2fb237a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(evaluations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "344a06a2-456d-4669-a1c2-e04a68d37444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "PARTLY_RELEVANT    0.435\n",
       "RELEVANT           0.355\n",
       "NON_RELEVANT       0.210\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3232988-5f84-4d2a-9e4c-ec91d321c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt-3.5-turbo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e9aefb4-24b2-4a97-b41f-0b970aa1d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The more reliable place to buy oysters in Newc...</td>\n",
       "      <td>12975</td>\n",
       "      <td>What is a more reliable place to buy oysters i...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer mentions a market in Ball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Based on the context provided, there is a list...</td>\n",
       "      <td>345</td>\n",
       "      <td>Is there a list of items related to great look?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer references a 'primal diet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dietary changes that can help with detoxifying...</td>\n",
       "      <td>1229</td>\n",
       "      <td>What dietary changes can help with detoxifying...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer includes incorrect and mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>There is no specific mention of benefits exper...</td>\n",
       "      <td>1455</td>\n",
       "      <td>What are the benefits you experienced from eat...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Based on the CONTEXT provided, Africans do not...</td>\n",
       "      <td>2403</td>\n",
       "      <td>Why do Africans not have yellow irises?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer     id  \\\n",
       "1   The more reliable place to buy oysters in Newc...  12975   \n",
       "10  Based on the context provided, there is a list...    345   \n",
       "11  Dietary changes that can help with detoxifying...   1229   \n",
       "18  There is no specific mention of benefits exper...   1455   \n",
       "29  Based on the CONTEXT provided, Africans do not...   2403   \n",
       "\n",
       "                                             question     relevance  \\\n",
       "1   What is a more reliable place to buy oysters i...  NON_RELEVANT   \n",
       "10    Is there a list of items related to great look?  NON_RELEVANT   \n",
       "11  What dietary changes can help with detoxifying...  NON_RELEVANT   \n",
       "18  What are the benefits you experienced from eat...  NON_RELEVANT   \n",
       "29            Why do Africans not have yellow irises?  NON_RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "1   The generated answer mentions a market in Ball...  \n",
       "10  The generated answer references a 'primal diet...  \n",
       "11  The generated answer includes incorrect and mi...  \n",
       "18  The generated answer does not provide any info...  \n",
       "29  The generated answer does not address the ques...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "733fef3f-3301-447d-b876-209745d661f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6294da6949440bbf812fe6575b7c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8949febb-a42e-4a55-b43f-fe0f33855ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e6c8750-3480-4b6e-8104-d1d98de82e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "PARTLY_RELEVANT    0.5\n",
       "RELEVANT           0.3\n",
       "NON_RELEVANT       0.2\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc6ca544-fc8f-4a1e-b21c-49fe22116c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a4639-c46c-4ed2-8dcc-9f87ecb7c67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
