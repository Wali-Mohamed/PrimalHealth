{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d49684-2a2e-44f6-b1c1-14ae38f307c8",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b30345-8175-485c-8a92-9b04c611317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import minsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfab572f-74f9-44e7-8dbb-cccfd579e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/final_data_with_IDs_new.csv')\n",
    "\n",
    "documents = df.to_dict(orient='records')\n",
    "import json\n",
    "with open('../data/clean_data/documents.json', 'w') as file:\n",
    "    json.dump(documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49255aa6-4022-41a9-b49c-bf5fc92010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'Chunked_Content': \"when you eat it alone?. Good idea to eat it once wuth honey and once alone My kids eat it with the meal.They aren't at home btw meals I will do it during week end Yesterday I had nausea after several hours passed from second meal.Today I had zero hunger until 20h+ passed after previous that meal Today I made only one typical meal enhanced with 4 egg yolks\",\n",
       " 'number of sentences': 2,\n",
       " 'number of words': 69}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d07a1f-7d0d-44f1-a77d-96b8d79f0055",
   "metadata": {},
   "source": [
    "### Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a1adb3-32f2-46b1-b46e-9f5f9771ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided not to use keywords as I discovered that it was helping with hit rate but slightly lowering it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29e0bad-a82e-4b4d-bbbd-07bbf906903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['Chunked_Content'],\n",
    "    keyword_fields=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983e54e9-2c7b-4848-8482-19d4cf589a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x24054755e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341a55cb-be6e-48ac-9a8f-15e72cae0f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x24054755e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a56dcae-f7aa-4b0a-902e-02f31686f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chunked_Content']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f726cf-66d5-48f3-b9f0-0ca6e0a5569c",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb1a91f-efac-4e76-8671-b02840b45561",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "477dc7f6-b597-4938-b478-e1c64e32587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I lose belly fat?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ed55640-6a68-4d51-bca4-872f8a6d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da200554-c9b4-4c25-bb3c-2669be2b548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5553,\n",
       "  'Chunked_Content': 'How much fat do you eat ?',\n",
       "  'number of sentences': 1,\n",
       "  'number of words': 7},\n",
       " {'id': 548,\n",
       "  'Chunked_Content': 'How do i do it?',\n",
       "  'number of sentences': 1,\n",
       "  'number of words': 5},\n",
       " {'id': 4964,\n",
       "  'Chunked_Content': 'How do I check for body fat?',\n",
       "  'number of sentences': 1,\n",
       "  'number of words': 7},\n",
       " {'id': 961,\n",
       "  'Chunked_Content': 'How?',\n",
       "  'number of sentences': 1,\n",
       "  'number of words': 1},\n",
       " {'id': 1734,\n",
       "  'Chunked_Content': 'So how can it breakdown inside us?. With enzyme and bile for sure but that takes time and a lot of effort if bacterias are lacking especially.. I feel better with long simmered meat fat or in broth than eating raw beef fat.... I wonder raw animal fat maybe not as healing as I expect.. Maybe we need to cook the fat and break it down before digest it?. Especially tough fat, pork belly.. The only chewy part in a cow are sirloin, organ mean and suet.. Beef belly for example, is almost impossible for me to chew Idk fermentation is the oldest cooking tho But on prosciutto fat is soft!!. Wonder if dry aging has a diff microbe effect than wet fermenting!!ü§î Did you just have high meatüòÇüòÇ ü§£ü§∑üèª\\u200d‚ôÄÔ∏è I tried that how I figured out it didn‚Äôt work Soft fat maybe and I think jialin knows that better than I do and i am mostly doing carnivore.. I was into the whole cooked carnivore diet, then heard about people eating meat raw.. üòÇ Never.. I even had commercial store chicken liver and duck gizzard and fermented them for 2 weeks.. Super gross.. But I still didn‚Äôt get sick Yep üòÇ Lol',\n",
       "  'number of sentences': 14,\n",
       "  'number of words': 203}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6250adf1-12b3-480f-b33d-c3ec6608b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The normal body temperature for a healthy human typically ranges from about 97¬∞F to 99¬∞F (36.1¬∞C to 37.2¬∞C). The average body temperature is often cited as 98.6¬∞F (37¬∞C), but it's important to note that individual temperatures can vary due to factors such as age, gender, time of day, and activity levels.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM response\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71f98d5-c162-4700-9ca7-2f9d6e8abd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38c4f49c-a547-4515-8fbc-2b36a5595d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    entry_template = \"\"\"\n",
    "    Chunked_Content: {Chunked_Content}\n",
    "    \"\"\".strip()\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c907faaf-a485-46ad-9060-124443fa2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "397591c9-4df9-47ab-b277-01011c0603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='how do I lose belly fat?'\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b57145f-c05e-46a9-b245-77bfb93a3d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "    \n",
      "    QUESTION: how do I lose belly fat?\n",
      "    \n",
      "    CONTEXT:\n",
      "    Chunked_Content: How much fat do you eat ?\n",
      "\n",
      "Chunked_Content: How do i do it?\n",
      "\n",
      "Chunked_Content: How do I check for body fat?\n",
      "\n",
      "Chunked_Content: How?\n",
      "\n",
      "Chunked_Content: So how can it breakdown inside us?. With enzyme and bile for sure but that takes time and a lot of effort if bacterias are lacking especially.. I feel better with long simmered meat fat or in broth than eating raw beef fat.... I wonder raw animal fat maybe not as healing as I expect.. Maybe we need to cook the fat and break it down before digest it?. Especially tough fat, pork belly.. The only chewy part in a cow are sirloin, organ mean and suet.. Beef belly for example, is almost impossible for me to chew Idk fermentation is the oldest cooking tho But on prosciutto fat is soft!!. Wonder if dry aging has a diff microbe effect than wet fermenting!!ü§î Did you just have high meatüòÇüòÇ ü§£ü§∑üèª‚Äç‚ôÄÔ∏è I tried that how I figured out it didn‚Äôt work Soft fat maybe and I think jialin knows that better than I do and i am mostly doing carnivore.. I was into the whole cooked carnivore diet, then heard about people eating meat raw.. üòÇ Never.. I even had commercial store chicken liver and duck gizzard and fermented them for 2 weeks.. Super gross.. But I still didn‚Äôt get sick Yep üòÇ Lol\n",
      "To lose belly fat, focus on consuming a diet rich in high-quality fats and proteins while minimizing processed foods. Cooking fats, such as long-simmered meat fat or broth, may be more beneficial for digestion compared to raw fats. Consider incorporating a carnivore-style diet, which emphasizes animal products, as this may help in addressing body fat. It‚Äôs also essential to pay attention to how your body responds to different types of fat and adjust accordingly. Remember, a balanced approach is important for overall health.\n"
     ]
    }
   ],
   "source": [
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ab9ef-8fd2-470b-b836-a46974ad01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3401b9-37ff-458e-80b6-cc423237b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce4a19-a321-469f-a474-a4345f5dd326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4380d-3328-4228-b570-0066cdfc97de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dcdbb-93b6-4821-8f48-ef8a74e6f324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f955e-a507-4ba1-a4d6-315394238007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38bdb0d2-4ca6-4564-84e7-6cc4ee20a935",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb4f7e6e-112a-4edd-a582-e84e82bc3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('../data/clean_data/ground-truth-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6c70fcd-2378-4447-8434-1e5e37bc679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "# print(len(df_questions))\n",
    "# # I will slice it to save time\n",
    "# df_questions_5000=df_questions.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9e4f21d-fd20-4e3a-866a-97eee735988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth=df_questions.to_dict(orient='records')\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd268389-6545-444a-985a-5cee677df68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does cutting hair hurt so much?\n",
      "How can egg whites help in hairstyling?\n",
      "What are some alternatives to egg whites for hair styling?\n",
      "Is it common to avoid washing meat?\n",
      "What are the potential risks of not washing meat?\n",
      "What benefits does rotten kidney have for kidney health?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)\n",
    "for q in ground_truth[0:6]:\n",
    "    print(q['question'])\n",
    "type(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d641e326-5c48-46b1-97fb-93a06837dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc09a27d-e890-490a-912b-f08f9922ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "673d9136-8be6-4e9d-8991-588da22fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b3eebcc9-f0e5-47df-83d9-23491b86fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b208267a-e1aa-43d5-8aaf-e7528fc8a1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bdf329c75a4b62bb6e3c1764d00945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5573333333333333, 'mrr': 0.3611481481481479}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b26956-ce63-416f-85bb-9c8154609701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'hit_rate': 0.365, 'mrr': 0.21138730158730154} # with 1000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cccd83a8-b44b-443d-9a38-22e524e67054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}# with 5000 rows of ground-truth questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1ab90-92e8-4e8e-b4ce-91db57ff5abf",
   "metadata": {},
   "source": [
    "### Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "64019bd7-fc1d-4485-b76a-001f0021e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_questions[:100]\n",
    "df_test = df_questions[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a81f8226-2c55-446e-a980-c4ad8c007f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c6dab3e-4fde-43f3-bfa2-9cdc178d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "81c09c4c-228c-404e-ab87-21e4ce04c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4df0cc6-c6c3-41a7-99fb-f7e5ead85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'Chunked_Content': (0.0, 3.0),\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d45dee4-ed23-4a5a-ba4f-300db9d29c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18880adf3bd47dcbe2eb3387a94729b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e871bc928e1f433184e333499808905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f00e30ff0f34f148f1d664ccf287575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc63f19368a47748d6dac8b9fdd2bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fa671e052040fb992843b72643ac58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458ea696edd449dcb5544f93fdcdeaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a9b8776cb440688ea788f970f6babc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7eea23beed46d5aa18a2edf4f59b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0cd79dc19342df90a2aaa25d05fc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da53d6f6e6ce47ca8c486ada47045374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1de2c89f81643bba7300dc1bdd9a7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9588ad8c74564123bc27d4c2249cfd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec054125fea4448a492c04ce8fed571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81152f6db7a469fb8c1293ccea7d5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b946e2e778ec4d57b11717c944792ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3989737948b4a59898aa939ce39dde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb13313f4e2947779d88b701117e7ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d75511da4eb402ea415c05a3471c6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25db4f766e794404a87192e8e160828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37528611a124f9d94c90c20612b1966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'Chunked_Content': 1.9366969407339725}, 0.46038492063492065)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e61a1a7a-24d5-4393-addc-c878007d803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4025dee33d3f402ab47d564e77083077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5573333333333333, 'mrr': 0.3611481481481479}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "    'Chunked_Content': 1.9366969407339725   \n",
    "    \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3e339-07b4-4e28-80e2-632a770e5950",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a02ae322-57b2-4066-8331-b3e5e061bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb793c64-af79-4398-88c6-2b881799f996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "55d2bf40-4fb6-49fa-a1ad-5d19c7fa47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3392, 'question': 'Why does cutting hair hurt so much?'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4991fe79-f4d0-4086-ae0e-efb27e40bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context provided does not give any information regarding the pain associated with cutting hair. Therefore, I cannot provide an answer based on the given context.\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "question = record['question']\n",
    "answer_llm = rag(question)\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86abda30-f17c-4c3b-bb90-35227e37c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Why does cutting hair hurt so much?\n",
      "Generated Answer: The context provided does not give any information regarding the pain associated with cutting hair. Therefore, I cannot provide an answer based on the given context.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "964641f2-5950-4e88-88a2-5702cf756e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aa07007e-f7f9-46df-b7a6-d5912d4429c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_questions.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "826ec05c-5d53-4d54-85ff-f68bae5bc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eeee6fd1-cae7-4df5-8bd0-756b4429ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b98f758884ab28e18c076e352b7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model='gpt-3.5-turbo') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22cddc4d-3dd0-4acf-bf38-d3c8c1d95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d09b74b1-4fc8-4c2c-96c6-666a2fb237a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(evaluations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ff2236f6-0456-4d6d-a1f0-427048edf0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           104\n",
       "PARTLY_RELEVANT     82\n",
       "NON_RELEVANT        14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "344a06a2-456d-4669-a1c2-e04a68d37444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.52\n",
       "PARTLY_RELEVANT    0.41\n",
       "NON_RELEVANT       0.07\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3232988-5f84-4d2a-9e4c-ec91d321c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt-3.5-turbo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e9aefb4-24b2-4a97-b41f-0b970aa1d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Based on the context provided, suggesting some...</td>\n",
       "      <td>3429</td>\n",
       "      <td>Why do you suggest someone should be quiet?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I'm sorry, I couldn't find any humorous insigh...</td>\n",
       "      <td>1220</td>\n",
       "      <td>What humorous insights can you share about hea...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Based on the context provided, the sensations ...</td>\n",
       "      <td>467</td>\n",
       "      <td>What sensations did you primarily feel?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Based on the context provided from the primal ...</td>\n",
       "      <td>3436</td>\n",
       "      <td>What are the current ingredient amounts I have...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Politicians are not specifically described in ...</td>\n",
       "      <td>3823</td>\n",
       "      <td>How are politicians described in terms of thei...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer    id  \\\n",
       "15  Based on the context provided, suggesting some...  3429   \n",
       "21  I'm sorry, I couldn't find any humorous insigh...  1220   \n",
       "46  Based on the context provided, the sensations ...   467   \n",
       "57  Based on the context provided from the primal ...  3436   \n",
       "71  Politicians are not specifically described in ...  3823   \n",
       "\n",
       "                                             question     relevance  \\\n",
       "15        Why do you suggest someone should be quiet?  NON_RELEVANT   \n",
       "21  What humorous insights can you share about hea...  NON_RELEVANT   \n",
       "46            What sensations did you primarily feel?  NON_RELEVANT   \n",
       "57  What are the current ingredient amounts I have...  NON_RELEVANT   \n",
       "71  How are politicians described in terms of thei...  NON_RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "15  The generated answer does not address the ques...  \n",
       "21  The generated answer does not provide any humo...  \n",
       "46  The generated answer does not address the sens...  \n",
       "57  The generated answer does not provide any info...  \n",
       "71  The generated answer does not address the ques...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "733fef3f-3301-447d-b876-209745d661f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b52fe9bf2f4b779a08b97fb8653bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o_mini = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o-mini') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o_mini.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8949febb-a42e-4a55-b43f-fe0f33855ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o_mini, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e6c8750-3480-4b6e-8104-d1d98de82e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.59\n",
       "PARTLY_RELEVANT    0.36\n",
       "NON_RELEVANT       0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bc6ca544-fc8f-4a1e-b21c-49fe22116c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt_4o_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "833a4639-c46c-4ed2-8dcc-9f87ecb7c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcd9df942de40d9abc3c6cddf2318b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c269feef-bd9a-47ed-b3ec-648d6cb033df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4e68a040-f7cf-4ee0-807a-0783f8762800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.660\n",
       "PARTLY_RELEVANT    0.285\n",
       "NON_RELEVANT       0.055\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfe30862-4334-4556-8708-913b1a99a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a3c3c-1c7c-4904-b42c-cb15e61d9dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
