{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d49684-2a2e-44f6-b1c1-14ae38f307c8",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b30345-8175-485c-8a92-9b04c611317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import minsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf3106a-1943-423b-aef9-80a8b24ffcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/data_chunked_5s.csv')\n",
    "\n",
    "documents = df.to_dict(orient='records')\n",
    "import json\n",
    "with open('../data/clean_data/documents.json', 'w') as file:\n",
    "    json.dump(documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4749d5e4-c364-4c3a-ab29-d56b84a4ded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "content                0\n",
       "number of sentences    0\n",
       "number of words        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49255aa6-4022-41a9-b49c-bf5fc92010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'content': 'this is the first I see an egg in bath ingredients and egg?. The plastic might even be better (especially if you have hard plastic) considering you have the cloth in between, because stainless steel could draw EMFs Your love Better anything non processed.. Sea water, an egg, sea salt, ACV, a little Urine.. .. .',\n",
       " 'number of sentences': 5,\n",
       " 'number of words': 56}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d07a1f-7d0d-44f1-a77d-96b8d79f0055",
   "metadata": {},
   "source": [
    "### Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a1adb3-32f2-46b1-b46e-9f5f9771ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided not to use keywords as I discovered that it was helping with hit rate but slightly lowering it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a29e0bad-a82e-4b4d-bbbd-07bbf906903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['content'],\n",
    "    keyword_fields=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61a97d-d7a5-4c79-bc4f-580eb4e85ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "983e54e9-2c7b-4848-8482-19d4cf589a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x1d8fd3e15e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "341a55cb-be6e-48ac-9a8f-15e72cae0f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x1d8fd3e15e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a56dcae-f7aa-4b0a-902e-02f31686f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f726cf-66d5-48f3-b9f0-0ca6e0a5569c",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb1a91f-efac-4e76-8671-b02840b45561",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477dc7f6-b597-4938-b478-e1c64e32587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I lose belly fat?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ed55640-6a68-4d51-bca4-872f8a6d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da200554-c9b4-4c25-bb3c-2669be2b548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6250adf1-12b3-480f-b33d-c3ec6608b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Losing belly fat involves a combination of dietary changes, physical activity, and lifestyle modifications. Here are some effective strategies:\\n\\n### Dietary Changes\\n1. **Balanced Diet**: Focus on whole foods such as fruits, vegetables, whole grains, lean proteins, and healthy fats.\\n2. **Reduce Sugar Intake**: Limit consumption of sugary foods and beverages, as excess sugar can contribute to fat accumulation.\\n3. **Healthy Fats**: Incorporate sources of healthy fats, such as avocados, nuts, seeds, and olive oil, while avoiding trans fats found in processed foods.\\n4. **Increase Protein**: Higher protein intake can help you feel fuller longer and can aid in maintaining muscle mass during weight loss.\\n5. **Portion Control**: Be mindful of portion sizes to avoid overeating, even healthy foods.\\n6. **Stay Hydrated**: Drink plenty of water throughout the day and consider reducing sugary drinks and alcohol.\\n\\n### Physical Activity\\n1. **Cardiovascular Exercise**: Engage in regular cardiovascular workouts like walking, running, cycling, or swimming to help burn calories.\\n2. **Strength Training**: Incorporate strength training exercises at least two times a week to build muscle, which can boost your metabolism.\\n3. **Core Workouts**: Include exercises that target the core muscles, such as planks, crunches, and leg raises, to strengthen and tone the abdominal area.\\n\\n### Lifestyle Modifications\\n1. **Sleep**: Aim for 7-9 hours of quality sleep each night; poor sleep can affect hormones that regulate appetite and fat storage.\\n2. **Manage Stress**: High stress levels can lead to weight gain, especially around the belly, due to the hormone cortisol. Practice stress-reduction techniques such as mindfulness, meditation, or yoga.\\n3. **Be Consistent**: Stick to your plan and make gradual changes that you can maintain over time.\\n\\n### Track Your Progress\\n- **Set Realistic Goals**: Aim for steady weight loss, such as 1-2 pounds per week, rather than quick fixes.\\n- **Monitor Your Intake**: Consider keeping a food diary or using a tracking app to monitor your diet and exercise.\\n\\n### Consult a Professional\\nIf needed, consider consulting a healthcare professional, dietitian, or personal trainer to tailor a plan specific to your needs and goals.\\n\\nRemember, it's important to focus on overall health rather than just appearance, and fat loss can take time and dedication.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM response\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e71f98d5-c162-4700-9ca7-2f9d6e8abd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38c4f49c-a547-4515-8fbc-2b36a5595d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_prompt(query, search_results):\n",
    "#     prompt_template = \"\"\"\n",
    "#     You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "#     Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "#     QUESTION: {question}\n",
    "    \n",
    "#     CONTEXT:\n",
    "#     {context}\n",
    "#     \"\"\".strip()\n",
    "    \n",
    "#     entry_template = \"\"\"\n",
    "#     Chunked_Content: {Chunked_Content}\n",
    "#     \"\"\".strip()\n",
    "#     context = \"\"\n",
    "    \n",
    "#     for doc in search_results:\n",
    "#         context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "#     prompt = prompt_template.format(question=query, context=context).strip()\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc9c465f-519c-4458-b1e5-79b947777dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    entry_template = \"\"\"\n",
    "    Chunked_Content: {content}\n",
    "    \"\"\".strip()\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac0c2121-9468-4f30-b12e-86b6fb31a176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n    \\n    QUESTION: how to lower blood pressure\\n    \\n    CONTEXT:\\n    Chunked_Content: She‚Äôs on the low blood pressure medication for 3 years.. High blood pressure so it makes hers low.. Fuuuck insane how people are tormented.. But will never change their ways to eat a way they can be nourished the way God designed.. I bought some one time.\\n\\nChunked_Content: The correct height for a human being is 7‚Äô0 minimum.. The proof is all around you.. These vaccines are worse than previously believed or studied to be.. Aajonus said paranoia is caused by low blood pressure aka toxins in blood.. Aka no blood going to the certain parts of the brain in the correct amount.\\n\\nChunked_Content: üòÅ We practice judo with bears brother Real fighting stock Okay brother, meet me in mountain.. I am from real mountain brother Mistake #1 Mold doesn\\'t appear if you keep the jar out.. Mold needs darkness.. Mistake #2 Mold won\\'t appear in a cold place like a fridge.. The place should be dark and warm üëç ok tell me place has anyone found that blood pressure study in england around 2006 i think that said lower blood pressure increased heart attack frequency?\\n\\nChunked_Content: I never found much in the books but vaguely recall something from the talks and Owanza being nuts about em Aajonus would say to wean off themif there is high blood pressure it\\'s to push through congestion according to aajonuscertain foods which act as solvent can help with it, like vinegar or unripe pineapple.. best to eat them with fat.. so if you make something like a sort of sauce with raw butter and a bit of vinegar inside, or a drink with some raw cream and some unripe pineapple, it can blast through stuffraw garlic can regulate blood pressure up or down depending on body needshalf a grapefruit can also, but there are compatibility problems with some heart medication so be careful How many moldy raspberries did aaj say to eat at one time?. Is it 3 berries once a week?. Also, he is on blood thinners because he has some sort of heart issue, if I were to tell him to stop taking blood thinners would I need to replace it with anything more \"natural\"?\\n\\nChunked_Content: In the non-MMS-exposed blood, there is no panic, just a slow acceptance of the death that ensues when blood is exposed to oxygen out of the blood stream.. In the blood exposed to MMS, watch the white blood cells eat the MMS, trying to protect the red blood cells from contact with MMS.. Time the blood cells‚Äô decomposition.. In an hour, compare the coloration of the dried blood masses.. Repeat the experiment several times.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='how to lower blood pressure'\n",
    "search_results=search(query)\n",
    "build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "773b99bf-f091-456b-aca6-f14cb9b5bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "    \n",
      "    QUESTION: how to lower blood pressure\n",
      "    \n",
      "    CONTEXT:\n",
      "    Chunked_Content: She‚Äôs on the low blood pressure medication for 3 years.. High blood pressure so it makes hers low.. Fuuuck insane how people are tormented.. But will never change their ways to eat a way they can be nourished the way God designed.. I bought some one time.\n",
      "\n",
      "Chunked_Content: The correct height for a human being is 7‚Äô0 minimum.. The proof is all around you.. These vaccines are worse than previously believed or studied to be.. Aajonus said paranoia is caused by low blood pressure aka toxins in blood.. Aka no blood going to the certain parts of the brain in the correct amount.\n",
      "\n",
      "Chunked_Content: üòÅ We practice judo with bears brother Real fighting stock Okay brother, meet me in mountain.. I am from real mountain brother Mistake #1 Mold doesn't appear if you keep the jar out.. Mold needs darkness.. Mistake #2 Mold won't appear in a cold place like a fridge.. The place should be dark and warm üëç ok tell me place has anyone found that blood pressure study in england around 2006 i think that said lower blood pressure increased heart attack frequency?\n",
      "\n",
      "Chunked_Content: I never found much in the books but vaguely recall something from the talks and Owanza being nuts about em Aajonus would say to wean off themif there is high blood pressure it's to push through congestion according to aajonuscertain foods which act as solvent can help with it, like vinegar or unripe pineapple.. best to eat them with fat.. so if you make something like a sort of sauce with raw butter and a bit of vinegar inside, or a drink with some raw cream and some unripe pineapple, it can blast through stuffraw garlic can regulate blood pressure up or down depending on body needshalf a grapefruit can also, but there are compatibility problems with some heart medication so be careful How many moldy raspberries did aaj say to eat at one time?. Is it 3 berries once a week?. Also, he is on blood thinners because he has some sort of heart issue, if I were to tell him to stop taking blood thinners would I need to replace it with anything more \"natural\"?\n",
      "\n",
      "Chunked_Content: In the non-MMS-exposed blood, there is no panic, just a slow acceptance of the death that ensues when blood is exposed to oxygen out of the blood stream.. In the blood exposed to MMS, watch the white blood cells eat the MMS, trying to protect the red blood cells from contact with MMS.. Time the blood cells‚Äô decomposition.. In an hour, compare the coloration of the dried blood masses.. Repeat the experiment several times.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c907faaf-a485-46ad-9060-124443fa2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "397591c9-4df9-47ab-b277-01011c0603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='how do I lose belly fat?'\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b57145f-c05e-46a9-b245-77bfb93a3d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To lose belly fat, it is suggested to adopt a primal diet approach that includes reducing carbohydrate intake, particularly from fruits and starches, as these can contribute to swelling and weight retention. Prioritize consuming healthy fats, as increasing fat intake may actually assist in fat loss by promoting a healthier metabolism. Additionally, some individuals on a low-carb or carnivore diet report losing fat specifically from the waist and belly while becoming healthier overall. Incorporating more animal fats instead of vegetable fats, and considering detoxification, might also help in effectively managing body fat.\n"
     ]
    }
   ],
   "source": [
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ab9ef-8fd2-470b-b836-a46974ad01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3401b9-37ff-458e-80b6-cc423237b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce4a19-a321-469f-a474-a4345f5dd326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4380d-3328-4228-b570-0066cdfc97de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dcdbb-93b6-4821-8f48-ef8a74e6f324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "999f955e-a507-4ba1-a4d6-315394238007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bdb0d2-4ca6-4564-84e7-6cc4ee20a935",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb4f7e6e-112a-4edd-a582-e84e82bc3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_questions = pd.read_csv('../data/clean_data/ground-truth-data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c70fcd-2378-4447-8434-1e5e37bc679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_questions))\n",
    "# # I will slice it to save time\n",
    "# df_questions_5000=df_questions.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e4f21d-fd20-4e3a-866a-97eee735988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth=df_questions.to_dict(orient='records')\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd268389-6545-444a-985a-5cee677df68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What makes you say that threatening your family is not acceptable?\n",
      "Why do you feel that someone needs to get a life?\n",
      "Have you experienced any recent threats to your family?\n",
      "What would you consider an appropriate response to someone threatening your family?\n",
      "Have you taken any steps to address these threats towards your family?\n",
      "Where can I find a thin silk floss that's unwaxed like silk thread?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)\n",
    "for q in ground_truth[0:6]:\n",
    "    print(q['question'])\n",
    "type(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d641e326-5c48-46b1-97fb-93a06837dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc09a27d-e890-490a-912b-f08f9922ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "673d9136-8be6-4e9d-8991-588da22fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3eebcc9-f0e5-47df-83d9-23491b86fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b208267a-e1aa-43d5-8aaf-e7528fc8a1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724ae8b779ca4b7ea916e218b2e53c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.762, 'mrr': 0.5635638888888886}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2b26956-ce63-416f-85bb-9c8154609701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'hit_rate': 0.365, 'mrr': 0.21138730158730154} # with 1000 rows\n",
    "#{'hit_rate': 0.541, 'mrr': 0.34330912698412647} after chunking 20 sentence per chunk\n",
    "#{'hit_rate': 0.5573333333333333, 'mrr': 0.3611481481481479} previous there are 100 sentence and also very short sentence\n",
    "#{'hit_rate': 0.762, 'mrr': 0.5635638888888886} data sliced from jan 2024 to september 2024 and limit 5 sentences \n",
    "#between 100 words to 400 words per chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cccd83a8-b44b-443d-9a38-22e524e67054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}# with 5000 rows of ground-truth questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1ab90-92e8-4e8e-b4ce-91db57ff5abf",
   "metadata": {},
   "source": [
    "### Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64019bd7-fc1d-4485-b76a-001f0021e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_questions[:100]\n",
    "df_test = df_questions[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a81f8226-2c55-446e-a980-c4ad8c007f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c6dab3e-4fde-43f3-bfa2-9cdc178d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81c09c4c-228c-404e-ab87-21e4ce04c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4df0cc6-c6c3-41a7-99fb-f7e5ead85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'content': (0.0, 4.0),\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d45dee4-ed23-4a5a-ba4f-300db9d29c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c967c8022e0c4b71a4f9c9a62a2558bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aad58e782a42eda69cbcc860be7417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d8610d020e4e97a02e8af5cfafcfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98818490ace7487880d72558cd8b7fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2820489bcf4a1fa0f4a04dc4f1369e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a96cec34d8435386b9714235b12aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861efc4afa074d57a37b2726d4075d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44138216d304ed4b6eefe254b989d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7534fed4f9f4729878dc9917e22c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c894088436d64f6fb8c78777183caa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2f6f6dfdac4f7e89b0d10df36e608b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0af17217204cc888deb8112260b641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0315258096407ca79fe610ddb63322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add0dc3f0834981a24cd15fccc325a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f369ea98864303955520cdb429dc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fb679f2dca49a791951e9d9a52b76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ac31eb221445729d6f4f44f6565497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc81c4127adf4365bbe7c1ff864038a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c23de19373b45b885d0b5b43d1c6704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df7e7c5db6746088cccf8f6ec232200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'content': 1.591310685457374}, 0.5565277777777778)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e61a1a7a-24d5-4393-addc-c878007d803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d730a160c394b16b202363326f782d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.762, 'mrr': 0.5635638888888886}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "    'content': 1.5913\n",
    "   \n",
    "    \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3e339-07b4-4e28-80e2-632a770e5950",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a02ae322-57b2-4066-8331-b3e5e061bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb793c64-af79-4398-88c6-2b881799f996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55d2bf40-4fb6-49fa-a1ad-5d19c7fa47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 608,\n",
       " 'question': 'What makes you say that threatening your family is not acceptable?'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4991fe79-f4d0-4086-ae0e-efb27e40bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threatening your family is deemed unacceptable as it poses a significant risk to their safety and well-being. This sentiment is echoed in the context, where the firm assertion \"Threatening my family is not acceptable\" emphasizes the seriousness of such actions and reinforces the importance of protecting loved ones.\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "question = record['question']\n",
    "answer_llm = rag(question)\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86abda30-f17c-4c3b-bb90-35227e37c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: What makes you say that threatening your family is not acceptable?\n",
      "Generated Answer: Threatening your family is deemed unacceptable as it poses a significant risk to their safety and well-being. This sentiment is echoed in the context, where the firm assertion \"Threatening my family is not acceptable\" emphasizes the seriousness of such actions and reinforces the importance of protecting loved ones.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "964641f2-5950-4e88-88a2-5702cf756e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa07007e-f7f9-46df-b7a6-d5912d4429c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_questions.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "826ec05c-5d53-4d54-85ff-f68bae5bc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeee6fd1-cae7-4df5-8bd0-756b4429ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f85b95389414ea8b9723e29a4e66e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model='gpt-3.5-turbo') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22cddc4d-3dd0-4acf-bf38-d3c8c1d95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d09b74b1-4fc8-4c2c-96c6-666a2fb237a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(evaluations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff2236f6-0456-4d6d-a1f0-427048edf0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           114\n",
       "PARTLY_RELEVANT     76\n",
       "NON_RELEVANT        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "344a06a2-456d-4669-a1c2-e04a68d37444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.57\n",
       "PARTLY_RELEVANT    0.38\n",
       "NON_RELEVANT       0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3232988-5f84-4d2a-9e4c-ec91d321c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt-3.5-turbo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e9aefb4-24b2-4a97-b41f-0b970aa1d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_eval[df_eval.relevance == 'NON_RELEVANT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fef3f-3301-447d-b876-209745d661f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4857ef674d42b8a667b6a576efe367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o_mini = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o-mini') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o_mini.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8949febb-a42e-4a55-b43f-fe0f33855ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o_mini, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e6c8750-3480-4b6e-8104-d1d98de82e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.59\n",
       "PARTLY_RELEVANT    0.36\n",
       "NON_RELEVANT       0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac69491a-dab4-43a3-bd41-76a9a1348da6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'relevance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21276\\479587235.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelevance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'relevance'"
     ]
    }
   ],
   "source": [
    "df.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc6ca544-fc8f-4a1e-b21c-49fe22116c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt_4o_mini.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "422567de-8437-463b-83d4-184868b59107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../data/clean_data/rag-eval-gpt_4o_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9777286-c8fb-49bc-a662-f722f795231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.57\n",
       "PARTLY_RELEVANT    0.38\n",
       "NON_RELEVANT       0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "833a4639-c46c-4ed2-8dcc-9f87ecb7c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcd9df942de40d9abc3c6cddf2318b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c269feef-bd9a-47ed-b3ec-648d6cb033df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4e68a040-f7cf-4ee0-807a-0783f8762800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.660\n",
       "PARTLY_RELEVANT    0.285\n",
       "NON_RELEVANT       0.055\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfe30862-4334-4556-8708-913b1a99a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147a3c3c-1c7c-4904-b42c-cb15e61d9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b1b6ca-b308-4db1-9408-4bc2474d1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/rag-eval-gpt4o.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4caa77-ee2a-441c-b4a3-70dfd32ceb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           137\n",
       "PARTLY_RELEVANT     55\n",
       "NON_RELEVANT         8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ca7312d-0103-48d6-9259-ef89d40dc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06439dd4-66ed-414f-93c2-9e1ccf95ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# df[df['relevance']=='PARTLY_RELEVANT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644952ae-4aa2-4acb-a9a6-a52af903881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RELEVANT', 'PARTLY_RELEVANT', 'NON_RELEVANT'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.relevance.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a5b1e-12f6-4105-b608-73535a69ece9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
