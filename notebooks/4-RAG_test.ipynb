{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d49684-2a2e-44f6-b1c1-14ae38f307c8",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b30345-8175-485c-8a92-9b04c611317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import minsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf3106a-1943-423b-aef9-80a8b24ffcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/data_chunked_5s.csv')\n",
    "\n",
    "documents = df.to_dict(orient='records')\n",
    "import json\n",
    "with open('../data/clean_data/documents.json', 'w') as file:\n",
    "    json.dump(documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4749d5e4-c364-4c3a-ab29-d56b84a4ded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "content                0\n",
       "number of sentences    0\n",
       "number of words        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49255aa6-4022-41a9-b49c-bf5fc92010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'content': 'this is the first I see an egg in bath ingredients and egg?. The plastic might even be better (especially if you have hard plastic) considering you have the cloth in between, because stainless steel could draw EMFs Your love Better anything non processed.. Sea water, an egg, sea salt, ACV, a little Urine.. .. .',\n",
       " 'number of sentences': 5,\n",
       " 'number of words': 56}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d07a1f-7d0d-44f1-a77d-96b8d79f0055",
   "metadata": {},
   "source": [
    "### Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a1adb3-32f2-46b1-b46e-9f5f9771ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided not to use keywords as I discovered that it was helping with hit rate but slightly lowering it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a29e0bad-a82e-4b4d-bbbd-07bbf906903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['content'],\n",
    "    keyword_fields=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61a97d-d7a5-4c79-bc4f-580eb4e85ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "983e54e9-2c7b-4848-8482-19d4cf589a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x281f33e5040>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "341a55cb-be6e-48ac-9a8f-15e72cae0f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x281f33e5040>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a56dcae-f7aa-4b0a-902e-02f31686f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.text_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f726cf-66d5-48f3-b9f0-0ca6e0a5569c",
   "metadata": {},
   "source": [
    "## RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb1a91f-efac-4e76-8671-b02840b45561",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "477dc7f6-b597-4938-b478-e1c64e32587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I lose belly fat?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed55640-6a68-4d51-bca4-872f8a6d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da200554-c9b4-4c25-bb3c-2669be2b548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6250adf1-12b3-480f-b33d-c3ec6608b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lowering blood pressure can often be achieved through lifestyle changes and, if needed, medication. Here are some effective strategies:\\n\\n### Dietary Changes\\n1. **Reduce Sodium Intake**: Aim for less than 2,300 mg of sodium per day. For most adults, 1,500 mg is even more effective.\\n2. **Eat More Fruits and Vegetables**: Aim for a diet rich in potassium, magnesium, and fiber. The DASH (Dietary Approaches to Stop Hypertension) diet is recommended.\\n3. **Limit Processed Foods**: These often contain high levels of sodium and unhealthy fats.\\n4. **Reduce Alcohol Consumption**: Limit alcohol to moderate levels‚Äîup to one drink per day for women and two for men.\\n5. **Choose Whole Grains and Lean Proteins**: Incorporate foods like oats, whole grain bread, chicken, beans, and fish.\\n\\n### Physical Activity\\n1. **Regular Exercise**: Aim for at least 150 minutes of moderate aerobic exercise (like walking or cycling) each week.\\n2. **Strength Training**: Incorporate muscle-strengthening activities at least two days a week.\\n\\n### Weight Management\\n1. **Maintain a Healthy Weight**: Losing even a small amount of weight can help lower blood pressure.\\n  \\n### Stress Management\\n1. **Practice Relaxation Techniques**: Try yoga, meditation, deep breathing exercises, or mindfulness.\\n2. **Get Enough Sleep**: Aim for 7-9 hours of quality sleep per night.\\n\\n### Monitor Blood Pressure\\n1. **Regular Monitoring**: Keep track of your blood pressure at home and consult with your healthcare provider.\\n\\n### Limit Caffeine\\n1. **Caffeine Consumption**: Be mindful of your intake, as it can cause a temporary spike in blood pressure.\\n\\n### Medication\\n- **Consult Your Doctor**: If lifestyle changes are not sufficient, your doctor may prescribe medications to manage your blood pressure.\\n\\n### Avoid Tobacco Products\\n1. **Quit Smoking**: Tobacco use can elevate blood pressure and have numerous other health impacts.\\n\\nIt‚Äôs always best to consult with a healthcare professional before making significant lifestyle changes or starting new treatments, especially if you have a health condition or are on medication.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LLM response\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": query}]\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e71f98d5-c162-4700-9ca7-2f9d6e8abd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c4f49c-a547-4515-8fbc-2b36a5595d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_prompt(query, search_results):\n",
    "#     prompt_template = \"\"\"\n",
    "#     You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "#     Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "#     QUESTION: {question}\n",
    "    \n",
    "#     CONTEXT:\n",
    "#     {context}\n",
    "#     \"\"\".strip()\n",
    "    \n",
    "#     entry_template = \"\"\"\n",
    "#     Chunked_Content: {Chunked_Content}\n",
    "#     \"\"\".strip()\n",
    "#     context = \"\"\n",
    "    \n",
    "#     for doc in search_results:\n",
    "#         context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "#     prompt = prompt_template.format(question=query, context=context).strip()\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc9c465f-519c-4458-b1e5-79b947777dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    entry_template = \"\"\"\n",
    "    Chunked_Content: {content}\n",
    "    \"\"\".strip()\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac0c2121-9468-4f30-b12e-86b6fb31a176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\\n    Use only the facts from the CONTEXT when answering the QUESTION.\\n    \\n    QUESTION: how to lower blood pressure\\n    \\n    CONTEXT:\\n    Chunked_Content: She‚Äôs on the low blood pressure medication for 3 years.. High blood pressure so it makes hers low.. Fuuuck insane how people are tormented.. But will never change their ways to eat a way they can be nourished the way God designed.. I bought some one time.\\n\\nChunked_Content: The correct height for a human being is 7‚Äô0 minimum.. The proof is all around you.. These vaccines are worse than previously believed or studied to be.. Aajonus said paranoia is caused by low blood pressure aka toxins in blood.. Aka no blood going to the certain parts of the brain in the correct amount.\\n\\nChunked_Content: üòÅ We practice judo with bears brother Real fighting stock Okay brother, meet me in mountain.. I am from real mountain brother Mistake #1 Mold doesn\\'t appear if you keep the jar out.. Mold needs darkness.. Mistake #2 Mold won\\'t appear in a cold place like a fridge.. The place should be dark and warm üëç ok tell me place has anyone found that blood pressure study in england around 2006 i think that said lower blood pressure increased heart attack frequency?\\n\\nChunked_Content: I never found much in the books but vaguely recall something from the talks and Owanza being nuts about em Aajonus would say to wean off themif there is high blood pressure it\\'s to push through congestion according to aajonuscertain foods which act as solvent can help with it, like vinegar or unripe pineapple.. best to eat them with fat.. so if you make something like a sort of sauce with raw butter and a bit of vinegar inside, or a drink with some raw cream and some unripe pineapple, it can blast through stuffraw garlic can regulate blood pressure up or down depending on body needshalf a grapefruit can also, but there are compatibility problems with some heart medication so be careful How many moldy raspberries did aaj say to eat at one time?. Is it 3 berries once a week?. Also, he is on blood thinners because he has some sort of heart issue, if I were to tell him to stop taking blood thinners would I need to replace it with anything more \"natural\"?\\n\\nChunked_Content: In the non-MMS-exposed blood, there is no panic, just a slow acceptance of the death that ensues when blood is exposed to oxygen out of the blood stream.. In the blood exposed to MMS, watch the white blood cells eat the MMS, trying to protect the red blood cells from contact with MMS.. Time the blood cells‚Äô decomposition.. In an hour, compare the coloration of the dried blood masses.. Repeat the experiment several times.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='how to lower blood pressure'\n",
    "search_results=search(query)\n",
    "build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "773b99bf-f091-456b-aca6-f14cb9b5bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a primal health adviser. Answer the QUESTION based on the CONTEXT from our primal diet database.\n",
      "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "    \n",
      "    QUESTION: how to lower blood pressure\n",
      "    \n",
      "    CONTEXT:\n",
      "    Chunked_Content: She‚Äôs on the low blood pressure medication for 3 years.. High blood pressure so it makes hers low.. Fuuuck insane how people are tormented.. But will never change their ways to eat a way they can be nourished the way God designed.. I bought some one time.\n",
      "\n",
      "Chunked_Content: The correct height for a human being is 7‚Äô0 minimum.. The proof is all around you.. These vaccines are worse than previously believed or studied to be.. Aajonus said paranoia is caused by low blood pressure aka toxins in blood.. Aka no blood going to the certain parts of the brain in the correct amount.\n",
      "\n",
      "Chunked_Content: üòÅ We practice judo with bears brother Real fighting stock Okay brother, meet me in mountain.. I am from real mountain brother Mistake #1 Mold doesn't appear if you keep the jar out.. Mold needs darkness.. Mistake #2 Mold won't appear in a cold place like a fridge.. The place should be dark and warm üëç ok tell me place has anyone found that blood pressure study in england around 2006 i think that said lower blood pressure increased heart attack frequency?\n",
      "\n",
      "Chunked_Content: I never found much in the books but vaguely recall something from the talks and Owanza being nuts about em Aajonus would say to wean off themif there is high blood pressure it's to push through congestion according to aajonuscertain foods which act as solvent can help with it, like vinegar or unripe pineapple.. best to eat them with fat.. so if you make something like a sort of sauce with raw butter and a bit of vinegar inside, or a drink with some raw cream and some unripe pineapple, it can blast through stuffraw garlic can regulate blood pressure up or down depending on body needshalf a grapefruit can also, but there are compatibility problems with some heart medication so be careful How many moldy raspberries did aaj say to eat at one time?. Is it 3 berries once a week?. Also, he is on blood thinners because he has some sort of heart issue, if I were to tell him to stop taking blood thinners would I need to replace it with anything more \"natural\"?\n",
      "\n",
      "Chunked_Content: In the non-MMS-exposed blood, there is no panic, just a slow acceptance of the death that ensues when blood is exposed to oxygen out of the blood stream.. In the blood exposed to MMS, watch the white blood cells eat the MMS, trying to protect the red blood cells from contact with MMS.. Time the blood cells‚Äô decomposition.. In an hour, compare the coloration of the dried blood masses.. Repeat the experiment several times.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c907faaf-a485-46ad-9060-124443fa2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "397591c9-4df9-47ab-b277-01011c0603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='how do I lose belly fat?'\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b57145f-c05e-46a9-b245-77bfb93a3d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To lose belly fat, consider focusing on a primal diet that emphasizes the consumption of healthy fats and minimizes carbohydrates, particularly from fruits and processed foods. Some individuals have reported that following a low-carb or carnivorous diet helps reduce fat specifically around the waist. Additionally, while losing weight can be challenging, many find that they may lose inches in their stomach without significant changes in overall weight. It's also suggested to detox from bad fats and incorporate good animal fats to support overall health and fat reduction. Regular monitoring of your diet and how your body responds may be beneficial in achieving your goals.\n"
     ]
    }
   ],
   "source": [
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ab9ef-8fd2-470b-b836-a46974ad01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3401b9-37ff-458e-80b6-cc423237b143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce4a19-a321-469f-a474-a4345f5dd326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4380d-3328-4228-b570-0066cdfc97de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dcdbb-93b6-4821-8f48-ef8a74e6f324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "999f955e-a507-4ba1-a4d6-315394238007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bdb0d2-4ca6-4564-84e7-6cc4ee20a935",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb4f7e6e-112a-4edd-a582-e84e82bc3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_questions = pd.read_csv('../data/clean_data/ground-truth-data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6c70fcd-2378-4447-8434-1e5e37bc679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_questions))\n",
    "# # I will slice it to save time\n",
    "# df_questions_5000=df_questions.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9e4f21d-fd20-4e3a-866a-97eee735988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth=df_questions.to_dict(orient='records')\n",
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd268389-6545-444a-985a-5cee677df68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What makes you say that threatening your family is not acceptable?\n",
      "Why do you feel that someone needs to get a life?\n",
      "Have you experienced any recent threats to your family?\n",
      "What would you consider an appropriate response to someone threatening your family?\n",
      "Have you taken any steps to address these threats towards your family?\n",
      "Where can I find a thin silk floss that's unwaxed like silk thread?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)\n",
    "for q in ground_truth[0:6]:\n",
    "    print(q['question'])\n",
    "type(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d641e326-5c48-46b1-97fb-93a06837dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc09a27d-e890-490a-912b-f08f9922ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "673d9136-8be6-4e9d-8991-588da22fa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3eebcc9-f0e5-47df-83d9-23491b86fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b208267a-e1aa-43d5-8aaf-e7528fc8a1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad39276474745b1827ac9f05b438b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.762, 'mrr': 0.5635638888888886}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2b26956-ce63-416f-85bb-9c8154609701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'hit_rate': 0.365, 'mrr': 0.21138730158730154} # with 1000 rows\n",
    "#{'hit_rate': 0.541, 'mrr': 0.34330912698412647} after chunking 20 sentence per chunk\n",
    "#{'hit_rate': 0.5573333333333333, 'mrr': 0.3611481481481479} previous there are 100 sentence and also very short sentence\n",
    "#{'hit_rate': 0.762, 'mrr': 0.5635638888888886} data sliced from jan 2024 to september 2024 and limit 5 sentences \n",
    "#between 100 words to 400 words per chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cccd83a8-b44b-443d-9a38-22e524e67054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'hit_rate': 0.3724, 'mrr': 0.21373825396825424}# with 5000 rows of ground-truth questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1ab90-92e8-4e8e-b4ce-91db57ff5abf",
   "metadata": {},
   "source": [
    "### Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64019bd7-fc1d-4485-b76a-001f0021e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_questions[:100]\n",
    "df_test = df_questions[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a81f8226-2c55-446e-a980-c4ad8c007f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c6dab3e-4fde-43f3-bfa2-9cdc178d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81c09c4c-228c-404e-ab87-21e4ce04c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4df0cc6-c6c3-41a7-99fb-f7e5ead85e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'content': (0.0, 4.0),\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d45dee4-ed23-4a5a-ba4f-300db9d29c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c967c8022e0c4b71a4f9c9a62a2558bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aad58e782a42eda69cbcc860be7417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d8610d020e4e97a02e8af5cfafcfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98818490ace7487880d72558cd8b7fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2820489bcf4a1fa0f4a04dc4f1369e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a96cec34d8435386b9714235b12aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861efc4afa074d57a37b2726d4075d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44138216d304ed4b6eefe254b989d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7534fed4f9f4729878dc9917e22c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c894088436d64f6fb8c78777183caa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2f6f6dfdac4f7e89b0d10df36e608b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0af17217204cc888deb8112260b641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0315258096407ca79fe610ddb63322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4add0dc3f0834981a24cd15fccc325a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f369ea98864303955520cdb429dc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fb679f2dca49a791951e9d9a52b76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ac31eb221445729d6f4f44f6565497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc81c4127adf4365bbe7c1ff864038a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c23de19373b45b885d0b5b43d1c6704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df7e7c5db6746088cccf8f6ec232200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'content': 1.591310685457374}, 0.5565277777777778)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e61a1a7a-24d5-4393-addc-c878007d803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d730a160c394b16b202363326f782d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.762, 'mrr': 0.5635638888888886}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "    'content': 1.5913\n",
    "   \n",
    "    \n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3e339-07b4-4e28-80e2-632a770e5950",
   "metadata": {},
   "source": [
    "## RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a02ae322-57b2-4066-8331-b3e5e061bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb793c64-af79-4398-88c6-2b881799f996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "55d2bf40-4fb6-49fa-a1ad-5d19c7fa47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3392, 'question': 'Why does cutting hair hurt so much?'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4991fe79-f4d0-4086-ae0e-efb27e40bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context provided does not give any information regarding the pain associated with cutting hair. Therefore, I cannot provide an answer based on the given context.\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "question = record['question']\n",
    "answer_llm = rag(question)\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86abda30-f17c-4c3b-bb90-35227e37c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Why does cutting hair hurt so much?\n",
      "Generated Answer: The context provided does not give any information regarding the pain associated with cutting hair. Therefore, I cannot provide an answer based on the given context.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "964641f2-5950-4e88-88a2-5702cf756e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aa07007e-f7f9-46df-b7a6-d5912d4429c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_questions.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "826ec05c-5d53-4d54-85ff-f68bae5bc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eeee6fd1-cae7-4df5-8bd0-756b4429ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b98f758884ab28e18c076e352b7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question,model='gpt-3.5-turbo') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "22cddc4d-3dd0-4acf-bf38-d3c8c1d95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d09b74b1-4fc8-4c2c-96c6-666a2fb237a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(evaluations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ff2236f6-0456-4d6d-a1f0-427048edf0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           104\n",
       "PARTLY_RELEVANT     82\n",
       "NON_RELEVANT        14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "344a06a2-456d-4669-a1c2-e04a68d37444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.52\n",
       "PARTLY_RELEVANT    0.41\n",
       "NON_RELEVANT       0.07\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b3232988-5f84-4d2a-9e4c-ec91d321c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt-3.5-turbo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e9aefb4-24b2-4a97-b41f-0b970aa1d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Based on the context provided, suggesting some...</td>\n",
       "      <td>3429</td>\n",
       "      <td>Why do you suggest someone should be quiet?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I'm sorry, I couldn't find any humorous insigh...</td>\n",
       "      <td>1220</td>\n",
       "      <td>What humorous insights can you share about hea...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any humo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Based on the context provided, the sensations ...</td>\n",
       "      <td>467</td>\n",
       "      <td>What sensations did you primarily feel?</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Based on the context provided from the primal ...</td>\n",
       "      <td>3436</td>\n",
       "      <td>What are the current ingredient amounts I have...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Politicians are not specifically described in ...</td>\n",
       "      <td>3823</td>\n",
       "      <td>How are politicians described in terms of thei...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               answer    id  \\\n",
       "15  Based on the context provided, suggesting some...  3429   \n",
       "21  I'm sorry, I couldn't find any humorous insigh...  1220   \n",
       "46  Based on the context provided, the sensations ...   467   \n",
       "57  Based on the context provided from the primal ...  3436   \n",
       "71  Politicians are not specifically described in ...  3823   \n",
       "\n",
       "                                             question     relevance  \\\n",
       "15        Why do you suggest someone should be quiet?  NON_RELEVANT   \n",
       "21  What humorous insights can you share about hea...  NON_RELEVANT   \n",
       "46            What sensations did you primarily feel?  NON_RELEVANT   \n",
       "57  What are the current ingredient amounts I have...  NON_RELEVANT   \n",
       "71  How are politicians described in terms of thei...  NON_RELEVANT   \n",
       "\n",
       "                                          explanation  \n",
       "15  The generated answer does not address the ques...  \n",
       "21  The generated answer does not provide any humo...  \n",
       "46  The generated answer does not address the sens...  \n",
       "57  The generated answer does not provide any info...  \n",
       "71  The generated answer does not address the ques...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "733fef3f-3301-447d-b876-209745d661f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b52fe9bf2f4b779a08b97fb8653bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o_mini = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o-mini') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o_mini.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8949febb-a42e-4a55-b43f-fe0f33855ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o_mini, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1e6c8750-3480-4b6e-8104-d1d98de82e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.59\n",
       "PARTLY_RELEVANT    0.36\n",
       "NON_RELEVANT       0.05\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bc6ca544-fc8f-4a1e-b21c-49fe22116c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt_4o_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "833a4639-c46c-4ed2-8dcc-9f87ecb7c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcd9df942de40d9abc3c6cddf2318b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_gpt4o = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question, model='gpt-4o') \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations_gpt4o.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c269feef-bd9a-47ed-b3ec-648d6cb033df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations_gpt4o, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4e68a040-f7cf-4ee0-807a-0783f8762800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.660\n",
       "PARTLY_RELEVANT    0.285\n",
       "NON_RELEVANT       0.055\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dfe30862-4334-4556-8708-913b1a99a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/clean_data/rag-eval-gpt4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147a3c3c-1c7c-4904-b42c-cb15e61d9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b1b6ca-b308-4db1-9408-4bc2474d1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_data/rag-eval-gpt4o.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ca7312d-0103-48d6-9259-ef89d40dc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06439dd4-66ed-414f-93c2-9e1ccf95ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_rows\", None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# df[df['relevance']=='PARTLY_RELEVANT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644952ae-4aa2-4acb-a9a6-a52af903881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RELEVANT', 'PARTLY_RELEVANT', 'NON_RELEVANT'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.relevance.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a5b1e-12f6-4105-b608-73535a69ece9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
